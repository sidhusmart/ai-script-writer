{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script-write your soap opera - Fifth Elephant workshop\n",
    "\n",
    "Welcome to the LLM fine-tuning workshop and thanks for your interest. In this session, we will walk you through the various steps in fine-tuning your own Large Language Model (LLM). This is a continuous area of research and evolution so the information contained here can change frequently. We have also made decisions for this workshop with the aim of simplifying the process and hope that it provides a great starting point from which participants can explore further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's build an AI script writer whom we can include in the writer's room\n",
    "\n",
    "The Writer's room is a fabled place where several writers that are working on a show come together with the Showrunner, Executive producer and others to write the script of a particular show. Each writer's room works and operates differently but they all include brainstorming for ideas, identifying characters, specific plot elements and in the end produce a detailed script for an episode for a series/show/play. The idea itself is not new and there has been research in this area even before the recent popularity of LLMs. In the LLM-era there have been two interesting ideas that stand out - [Showrunner Agents](https://fablestudio.github.io/showrunner-agents/) - where researchers built out an entire episode of South Park by combinging various types of LLM-based agents to work together. The other approach is a paper called [Dramatron (from Deepmind)](https://arxiv.org/pdf/2209.14958) which used a series of prompts that were used to create plays that were finally staged as well.\n",
    "\n",
    "In this workshop, we will take inspiration from the Dramatron paper to create our own scriptwriting assistant by fine-tuning our own LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described in the slides, here is a simple step-by-step approach to fine-tuning our own LLM.\n",
    "\n",
    "<a href=\"https://ibb.co/bQyLGNx\"><img src=\"https://i.ibb.co/mbYtPhm/Screenshot-2024-07-04-at-14-46-19.png\" alt=\"Screenshot-2024-07-04-at-14-46-19\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our training config\n",
    "\n",
    "We choose to use the Axolotl package for running our fine-tuning. It is a wrapper on top of various other packages and provides a simple but detailed configuration file where all parameters for a specific fine-tuning job are specified. There are also several example configurations available from which we can start and adapt as required - this provides a great onboarding experience.\n",
    "\n",
    "Let's take a look at what our configuration file looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Fine-tuning Dataset\n",
    "\n",
    "One of the most important aspects when fine-tuning an LLM is the dataset on which you would like to fine-tune. There are several datasets that are available on the HuggingFace datasets repository but this is also where your unique business advantage or proprietary data comes to play. For instance, let's say that you already run an app in production with multiple users adopting it, you would typically start by making use of GPT-3.5 or GPT-4 as the LLM. Over time, you likley run multiple LLM calls and store the historical information. Not all responses maybe accurate and you will also know what is actually the desired response. You would therefore use this data and annotate or label it manually. This could be a great asset for you to use and build a specific LLM that cannot be easily replaced and is also chepaer.\n",
    "\n",
    "For this workshop, since we are not dealing with an existing app as such we followed the route of creating a synthetic dataset with the help of OpenAI APIs. Basically, we take an existing example and ask the OpenAI LLM to create multiple other examples that follow the same style but add some diversity to the examples. You can also run this via a batch API that is cheaper - although you might need to wait upto 24 hours for it to process.\n",
    "\n",
    "As a good starting point for this workshop, I have already uploaded this dataset to HuggingFace so that participants can download and use it readily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Fine-tuning process\n",
    "\n",
    "We have our dataset, we have decided the configuration and now it's time to run our fine-tuning process. Till now we were dealing with conceptual topics and now we get to the nitty-gritty of making this whole thing work. This is typically also the point where you will run into the most number of issues. One of the biggest bottlenecks with fine-tuning LLMs is the requirement to have GPUs. The smallest models (with 7 billion parameters) are still quite large and not everyone has a GPU lying around. This is where it makes sense to leverage a cloud provider.\n",
    "In addition to that, many of the fine-tuning libraries are still work in progress with a lot of rough edges. So it's not uncommon to run into issues like installation dependencies, incorrect deployments when moving to the cloud and much else. \n",
    "\n",
    "Keeping the goal of this workshop in mind, we chose to make use of Modal Labs as the GPU provider and make use of a starter script that they have already created to get our fine-tuning job to run. This script takes care of multiple aspects of running a GPU training process like creating the necessarsy docker containers, kicking off a distributed training run, merging the LoRA at the end and finally also spinning up an inference server. We will obviously incur costs in this process but Modal also provides upto 30 USD of free credit with every account each month which should be enough for running many of our fine-tuning processes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Inference\n",
    "\n",
    "Now that we have trained our model, let us now try and see how it works - moment of truth!\n",
    "\n",
    "For running inference also there are several options. Modal allows you to have a serverless inference instance that can be spun up only for serving a single request and then it's shut down again. This way, you are not incurring GPU costs when there are no requests. Of course, the issue is that you will also have to run into start-up wait times. We can overcome this by creating a dedicated inference instance for our newly fine-tuned model and run it for a certain fixed period of time. This is what we will do in the following steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
